---
id: crawl-all-links
title: Crawl all links on a website
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

import CheerioSource from '!!raw-loader!./crawl_all_links_cheerio.js';
import PuppeteerSource from '!!raw-loader!./crawl_all_links_puppeteer.js';
import PlaywrightSource from '!!raw-loader!./crawl_all_links_playwright.js';

This example uses the `Apify.enqueueLinks()` method to add new links to the `RequestQueue` as the crawler navigates
from page to page. If only the required parameters are defined, all links will be crawled.

<Tabs groupId="crawler-type">

<TabItem value="cheerio_crawler" label="CheerioCrawler" default>
	Using `CheerioCrawler`:

	<CodeBlock className="language-js">
		{CheerioSource}
	</CodeBlock>
</TabItem>

<TabItem value="puppeteer_crawler" label="PuppeteerCrawler">
	Using `PuppeteerCrawler`:

	:::tip

	To run this example on the Apify Platform, select the `apify/actor-node-puppeteer-chrome` image for your Dockerfile.

	:::

	<CodeBlock className="language-js">
		{PuppeteerSource}
	</CodeBlock>
</TabItem>

<TabItem value="playwright_crawler" label="PlaywrightCrawler">
	Using `PlaywrightCrawler`:

	:::tip

	To run this example on the Apify Platform, select the `apify/actor-node-playwright-chrome` image for your Dockerfile.

	:::

	<CodeBlock className="language-js">
		{PlaywrightSource}
	</CodeBlock>
</TabItem>

</Tabs>
